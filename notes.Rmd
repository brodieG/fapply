# fapply

# Nex Steps

Need to demonstrate that we can load at least on UNIX alike.

# todo

* Check name isn't used already.
* Figure out how to access an entry point?  We can base on what R does, but
  clearly this is going to be system dependent and challenging.  Another
  argument for using R CMD SHLIB and dynload.

# Concept

1. Given a parsed R expression
2. Check that expression / function has symbols that resolve only to known
   functions.
3. Translate it into C code.
4. Compile it.
5. Feed it.

# What needs to happen

1. A compiled function that accepts N double pointers.
2. A manager to call the compiled function repeatedly with variations.

# Features

1. Standard arithmetic.
2. Sum. Mean.
3. Assignment?  Probably not.

# Translation

## Memory

* Calling function will allocate a vector sufficiently large to hold the
  largest result and pass that to each computing function.
* Computing functions may only write to that vector?  Specifically, computing
  functions may not allocate?

## Length Computation

Each known function should have some method of ex-ante determining the length of
the outputs as a function of the lengths of the inputs (e.g. `quantile` would be
the length of the `probs` argument).

## Simple arithmetic

Compute length of each vector.  Generate the full C expression with index or
pointer offset access.

Recycling a real problem; if we  have to do it we then need to compute modulo,
but this is only going to happen if the functions return weird lengths.

## Interface

### R Level

Each special function must be pre-registered with some mechanism to distinguish
which parameters are vector ones that will be fed, vs which one should be
evaluated immediately for dispatch decisions (e.g. `na.rm=TRUE`).

How does this work for a newly defined function at the R level?  Does it matter?

### C Level

Target function should accept an array of double pointers the same length as it
expects arguments.  All functions should be like that.

Parameters such as `na.rm=TRUE` actually cause dispatch to a different
function.  So when we register a function we need to declare this?  I guess it
should be optional and we use it to recreate `mean`, etc.

# Compilation

## Cost

For a super simple compile:

```
$ time clang -g -c -O2 test.c -o test.o

real	0m0.115s
user	0m0.065s
sys	0m0.045s
```

But first time calling clang can take a long time (e.g. 6 seconds).  One
question whether adding R stuff slows down the compilation.  Doing it with `R
CMD SHLIB` but then obviously gives us access to a lot more options:

```
time R CMD SHLIB test-r.c
clang -mmacosx-version-min=10.13 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I/usr/local/include   -fPIC  -Wall -g -O2  -fno-common -std=c99 -pedantic -Wall -Wextra -c test-r.c -o test-r.o
clang -mmacosx-version-min=10.13 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/Library/Frameworks/R.framework/Resources/lib -L/usr/local/lib -o test-r.so test-r.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation

real	0m0.361s
user	0m0.235s
sys	0m0.112s
```

Also, nice thing about R CMD SHLIB is that it abstracts away calling the
compiler (on windows)?  Oddly, calling the plain c file is slower!  Well, at
least not faster, so the overhead is from firing up make, etc.

> Note It's not actually slower as we need the extra step to generate the .so.

## Loading

Ideally we would be able to use `dyn.load`, but then we need `.Call` which
obviously we're trying to avoid.  This is going to be really complicated, see
"src/main/dodotcode.c".

# vs Rcpp?

How is this different to Rcpp?  Very limited, but no learning curve.  Only
doubles.

# Interface

```
fapply(X, INDEX, FUN)
```
