# To Do / Questions

## Vetr

* What about the case where you want to reference another argument in a vetting
  expression?  That gets interpreted as a template because the other parameter
  name is not `.`.
* Do we need to document that the `&&` and `||` tokens are lazy?

## Things to test

* `function(a) if(a) x else y`
* That it is impossible to try to use an allocation before it would be created
  in the code.  Tricky with loops.

## Current

* Do we need `id` if it's always just `seq_along(id)`.  Probably not, `id0`
  should be sufficient.

* In the allocation data, is it the case that `group` and `is.na(size)` are the
  same?  Maybe, but we need to think ahead to cases where we'll have sizes that
  will be e.g. `n * g + k` where `g` is group size (to allow `c`).

* What do we do about repeated external symbols getting added to the allocation
  table?  Shouldn't matter since it's the same memory location, but might be
  cleaner to only include once.

* Add a cleanup pass for `get_r_code` (and document that's being done).  Drop
  `...` in names, and maybe default args that are set to their default values.
  Harder but potentially useful is any arguments that are in the same order they
  were originally.  Maybe use something other than `.R2C_SUB_` as root.

* Profile a compilation call and track (maybe it doesn't matter because really
  it's all about that first compilation to load the tool chain).

* Is it okay for `square` to require `r2c` attached?  Inconsistent with what we
  do with `r2c_copy`.  A possible solution would be to implement `::`.  Then we
  could rename `r2c_copy` to `copy` or `copy_vec` (later to reduce collision
  with e.g. `data.table`).

* Think through the implications of using the lexical env for "r2c_fun"
  functions with respect to the future `r2c` function library.

* Make sure we think through the interaction of things with `sym.free` with
  variable assignment as that could cause problems since that assumed the only
  source of them was parameters.
* Does preproc `sym.free` `sym.bound` make sense now with `formals` supplied?

## Next

* Can we improve the stand-alone execution so it doesn't suffer the penalty of
  generating the useless group vector?  Do we care?

* Should we add `rm` statements (optionally) for `reuse_calls` use in R (not in
  `r2c` as there we track lifetime, and none of the allocations can be released
  until the end) to reduce peak memory usage?

* Can we mark some functions as okay to re-use memory, where the result can be
  one of the inputs?

* Identify unused assignments as a courtesy warning?  This could be extended to
  unused expressions, which could potentially be eliminated (possibly
  iteratively for e.g. `x <- y; z <- x` where then `z` is unused).

* `reuse_call` needs to track what the original call was so we can provide
  better error messages if something goes wrong at some point.

* Semi-internal error should issue conditions that can be caught by the
  compilers or runners to return as errors with a meaningful calling function
  instead of an internal function.
* Should we have safety tests in the code to be controlled by a debug mode flag?

* Look into the standalone R math library.

* Consider whether `x^2` -> `x * x` should be an optimization (especially given
  that `x` could be a complex expression (actual, this special case is handled
  with `square` which avoids the repetition).
* Now that we have `reuse_calls`, do we want to use `x * x` instead of `square`?
* Transformations probably should not be considered optimizations, because e.g.
  for `square` not applying it leads to non-identical results.


* Can we avoid `r2c_copy` in cases where we know the symbol is assigned to from
  an expression?  The big challenge is dealing with e.g. `if` and all the
  constraints that adds.

* Make sure vecrec works with `...`, e.g. as would be needed for `paste(...)`
  (although maybe that's not the best example given 0-len behavior).  Test would
  be to implement `pmax`.

* Reconcile binding of group names and assignment names?  A bit awkward now in
  `append_dat`.  What about `MoreArgs` names?

* Will be complicated to think how to convey complex sizes like the ones
  generated by `c` would be.

* For `if` and similar, how do we rationalize the same symbols being assigned to
  in different branches?  We need to ensure they are the same size, but also
  that they both use the same memory slot.
* Handle assignment to function symbols, etc?  There shouldn't be confusion with
  invocation, but if we ever implement `lapply`, etc?

* Unary arithmetic funs.
* Add post-processing of function result (e.g. to attach names, etc, as in
  `quantile`).

* Rename depth to height.  No, rename depth to level.  The use of height and
  depth with an upside down tree is ridiculous and not my fault.

* Support for functions with defaults that need to be evaluated?  No.  This
  substantially increases complexity because we have to do so in the function
  evaluation environment and need access to all the other arguments.  We could
  potentially support things like `quantile(..., seq(0, 1, .25))`.
* Side effects from evaluation of control parameters?  Where should assigned
  variables reside?  Update: we won't support non-literal (or limited anyway)
  control parameters.

* Can we get more memory efficient by e.g. using `+=`.  This is complicated, see
  notes "Memory Re-Use".

## Memory Re-Use

## Zero Len

## For CRAN

* Include README/extra contents in vignettes
* Figure out why winbuilder doesn't work.
* Errors in `match.call` that show the deparsed argument might deparse
  differently on different systems (`group_sum` error tests).
* Add iterator breaks?

## Other

* Add ability to use `::`?
* Make sure there are interrupts.  Can we use "R_ext/Intermacros.h".  It seems
  yes generally, but they are not explicitly part of the API, and then there is
  the question of whether it makes sense to do so, or if we should just be doing
  this at the group level?
* share `lcurry` with klutometis
  https://github.com/klutometis/R-functional/issues
* Make overflow testable.
* Group label generation should potentially return position of vector rather
  than actual label to allow flexible re-use of labels beyond just factors (i.e.
  we subset the input vector to generate the labels).
* Special case of constant result lengths could be an optimization for group
  where we don't have to generate the vector, although there should always be
  few groups relative to vector elements, so complexity not worth it?
* Migrate to tapply structure.  More generally, explain interface?
* Allow more then `INT_MAX` groups (labels are limiting right now)?
* What if compilation fails, do we have good error messages?
* Don't use double for group sizes unless we have groups that are too large.
  **probably not worth it** b/c the group sizes result is only as big as the
  number of groups, so very small in the grand scheme of things.  First level is
  simply to check input vector size, and if less than `INT_MAX` use that, next
  step would be to switch from int to double if we do have a vector that exceeds
  the size limit (but then we need to test for that...).  Does that mean we need
  a limit to int?  Will be annoying to have logic for both.
* Should sorted be "assume.sorted"?  Probably.  Could add check that it is (see
  next).
* Process groups might be able to determine that things are sorted?  If things
  are always e.g. increasing, then it must be the case that they are sorted.
  Evaluate the overhead of this; should be low as it would just be done in the
  second pass that stores the sizes?  Something still needs to be declared as
  sorted though.  It's relatively cheap to check that it is, but not so cheap
  that we would always want to run that check.
* Perhaps we got too lazy with POW, do we need to handle all the other cases
  arith handles?  Maybe, but if we do we'll likely need our own `pow` function,
  as it stands right now we're likely to get non-identical results in the case
  of NA or Inf (or at least particular variations of them).
* Re-implement modulo.
* The `check=TRUE` might be better done with an explicit check function.
* For running function directly, can we pass data as an env so the traceback
  doesn't explode (but make sure this doesn't cause reference / refcount issues)?
* What is the implementation cost of allowing internal functions to advance the
  data pointers so they don't have to be manually moved after each function
  iteration?
* Implement sum64 and mean64 to use double accumulator (note we've tested that
  double accumulators are slower).
* We can no longer use `mean <- mean.default` and `r2c` at same time (this might
  be correct, but will make readme a bit more complicated).  Also, error message
  is very confusing in this case as `mean.default` is also from the base
  namespace, even though the masking is defined at the global level.
* Add destructors that will unload the shlib and delete file file when the
  corresponding object is garbage collected (finalizer).
* Add check to `r2c` funs that verify the `r2c` version, the R version, and the
  platform (anything else)?
* Figure out a better way to store the object than embedding it with `bquote` in
  the function (e.g. retrieve from the call like `rlang`, but not sure that's
  better).
* Think about `df %>% group_by(g) %>% filter(x > min(df$x)`.  This should
  resolve naturally if we allow `[['x']]` as "normal" expression.
* Can we optimize label generation for cases where the last step is constant
  size or size of groups?
* Better introspection tools for intermediate products so we can see what they
  are.
* Are names sufficient to disqualify from nakedness?  How do names behave in
  recycling?  Do we want to allow other attributes to persist?
* Make sure to have a function that uses the `ctrl` functionality to check that
  it works properly (once we switch to `flag` for most functions).
* Make sure pointer arrays are aligned.  Use `malloc`?  If so internal code
  cannot use `error`, and we can't guarantee that?  Can we register a finalizer
  somehow (probably will need to).
* Make sure headers go in in correct order; it may not work if we structure
  workflow around C functions?  Maybe okay if each group of functions does the
  right thing?  Do we need to include the headers before each group of
  functions?  Do we need to keep translation units independent (but the lose the
  benefit of static funs)?  This is almost certainly a real problem that needs
  to be addressed.
* Ensure all entry point names are unique and that there are no collisions.
  Maybe this can be done on registration?
* Special case where all groups are same size and there is an external vector of
  that size?
* Add capability to specify functions in non-standard ways (e.g. `base::sum`, or
  `(get("sum", as.environment("package:base"))`)?  Maybe not, that seems like
  potential trouble.  Certainly document also things like `f <- sum; f(x)`.
* Is it faster to compute complex expressions pairwise (i.e. full vector scan of
  two vectors), or do each row in full once?
* Look into using R_GetCCallable (see WRE) instead of what we're doing now.  It
  seems though that to do so we'll need to generate a full package which will
  further slow down the compilation.  What does `inline` do?
* Check name isn't used already.
* `?SHLIB` states some binary distributions don't include `R CMD SHLIB`.
* Figure out how to call the current version of R (e.g. `RD CMD SHLIB`).
* See how far back this works in terms of R versions.
* What happens when this stuff is serialized?
* Is there an alternative to R_FindSymbol?  Can we get it to be made part of the
  API.
* Can we use this in some way for e.g. really wide matrices where each column
  takes the place of an argument?  Generating a pointer for each column then may
  be less efficient.
* Lags and similar (i.e. `x[i] = x[i] * x[i - 1]`).
* Re-use repeated expressions.

