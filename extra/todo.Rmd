# To Do / Questions

## Things to test

* That it is impossible to try to use an allocation before it would be created
  in the code.  Tricky with loops.
* Test corner cases such as a repeated assignment to see if it get correctly
  detected as being repeated.
* Check that forwarding calls in `...` works correctly, e.g.
  `sum(1 + x, 2 + y)`, not obvious from glancing at dots handling that it does.
* Reuse with an inner expression that appears separately from a re-used outer
  expression.
* Renames:
  * Don't change the structure of the tree
  * Can be reversed (maybe this covers the prior point)

## Current

* Make sure we understand when it's okay or not okay to assume about order of
  evaluation of parameters (e.g. when they contain assignments in them).
  Probably we'll just have to document that what we assume may be different than
  what R does, and it's a really bad idea to do this in the first place in a way
  where order matters.
* `reuse_call` needs to track what the original call was so we can provide
  better error messages if something goes wrong at some point.
* Make sure that the Function Environment in `r2cf` is captured somewhere.  In
  particular we want to make sure unbound symbols are resolved according to that
  environment.  Will also need to think about what this means for the `enclos`
  parameter to the runners.  This might also have implications for function
  libraries.
* Handle assignment to function symbols, etc?  There shouldn't be confusion with
  invocation, but if we ever implement `lapply`, etc?
* Identify unused assignments as a courtesy warning?
* Make sure we think through the interaction of things with `sym.free` with
  variable assignment as that could cause problems since that assumed the only
  source of them was parameters.
* Rename depth to height.  No, rename depth to level.  The use of height and
  depth with an upside down tree is ridiculous and not my fault.
* Does preproc `sym.free` `sym.bound` make sense now with `formals` supplied?
* Rename `r2c` to `r2cf` or similar once we implement functions.  Partly this is
  so `?r2c` will pull up the package docs, not the function docs.
* To allow assignments we can just use a series of nested environments such that
  each sub-call will then seek the symbol through the nested environments.
  We'll need to bind the data symbols to e.g. environments so they may be
  uniquely identified and we can confirm they've been found.  Err, what were we
  thinking here?
* Complex expressions with curly braces, etc.
* Unary arithmetic funs.
* Add post-processing of function result (e.g. to attach names, etc, as in
  `quantile`).
* Support for functions with defaults that need to be evaluated?  No.  This
  substantially increases complexity because we have to do so in the function
  evaluation environment and need access to all the other arguments.
* Side effects from evaluation of control parameters?  Where should assigned
  variables reside?
* Can we get more memory efficient by e.g. using `+=`.  This is complicated, see
  notes "Memory Re-Use".

## Memory Re-Use

## Zero Len

## For CRAN

* Include README/extra contents in vignettes
* Figure out why winbuilder doesn't work.
* Errors in `match.call` that show the deparsed argument might deparse
  differently on different systems (`group_sum` error tests).
* Add iterator breaks?

## Other

* Make sure there are interrupts.  Can we use "R_ext/Intermacros.h".  It seems
  yes generally, but they are not explicitly part of the API, and then there is
  the question of whether it makes sense to do so, or if we should just be doing
  this at the group level?
* share `lcurry` with klutometis
  https://github.com/klutometis/R-functional/issues
* Make overflow testable.
* Group label generation should potentially return position of vector rather
  than actual label to allow flexible re-use of labels beyond just factors (i.e.
  we subset the input vector to generate the labels).
* Special case of constant result lengths could be an optimization for group
  where we don't have to generate the vector, although there should always be
  few groups relative to vector elements, so complexity not worth it?
* Migrate to tapply structure.  More generally, explain interface?
* Allow more then `INT_MAX` groups (labels are limiting right now)?
* What if compilation fails, do we have good error messages?
* Don't use double for group sizes unless we have groups that are too large.
  **probably not worth it** b/c the group sizes result is only as big as the
  number of groups, so very small in the grand scheme of things.  First level is
  simply to check input vector size, and if less than `INT_MAX` use that, next
  step would be to switch from int to double if we do have a vector that exceeds
  the size limit (but then we need to test for that...).  Does that mean we need
  a limit to int?  Will be annoying to have logic for both.
* Should sorted be "assume.sorted"?  Probably.  Could add check that it is (see
  next).
* Process groups might be able to determine that things are sorted?  If things
  are always e.g. increasing, then it must be the case that they are sorted.
  Evaluate the overhead of this; should be low as it would just be done in the
  second pass that stores the sizes?  Something still needs to be declared as
  sorted though.  It's relatively cheap to check that it is, but not so cheap
  that we would always want to run that check.
* Perhaps we got too lazy with POW, do we need to handle all the other cases
  arith handles?  Maybe, but if we do we'll likely need our own `pow` function,
  as it stands right now we're likely to get non-identical results in the case
  of NA or Inf (or at least particular variations of them).
* Re-implement modulo.
* The `check=TRUE` might be better done with an explicit check function.
* For running function directly, can we pass data as an env so the traceback
  doesn't explode (but make sure this doesn't cause reference / refcount issues)?
* What is the implementation cost of allowing internal functions to advance the
  data pointers so they don't have to be manually moved after each function
  iteration?
* Implement sum64 and mean64 to use double accumulator (note we've tested that
  double accumulators are slower).
* We can no longer use `mean <- mean.default` and `r2c` at same time (this might
  be correct, but will make readme a bit more complicated).  Also, error message
  is very confusing in this case as `mean.default` is also from the base
  namespace, even though the masking is defined at the global level.
* Add destructors that will unload the shlib and delete file file when the
  corresponding object is garbage collected (finalizer).
* Add check to `r2c` funs that verify the `r2c` version, the R version, and the
  platform (anything else)?
* Figure out a better way to store the object than embedding it with `bquote` in
  the function (e.g. retrieve from the call like `rlang`, but not sure that's
  better).
* Think about `df %>% group_by(g) %>% filter(x > min(df$x)`.  This should
  resolve naturally if we allow `[['x']]` as "normal" expression.
* Can we optimize label generation for cases where the last step is constant
  size or size of groups?
* Better introspection tools for intermediate products so we can see what they
  are.
* Are names sufficient to disqualify from nakedness?  How do names behave in
  recycling?  Do we want to allow other attributes to persist?
* Make sure to have a function that uses the `ctrl` functionality to check that
  it works properly (once we switch to `flag` for most functions).
* Make sure pointer arrays are aligned.  Use `malloc`?  If so internal code
  cannot use `error`, and we can't guarantee that?  Can we register a finalizer
  somehow (probably will need to).
* Make sure headers go in in correct order; it may not work if we structure
  workflow around C functions?  Maybe okay if each group of functions does the
  right thing?  Do we need to include the headers before each group of
  functions?  Do we need to keep translation units independent (but the lose the
  benefit of static funs)?  This is almost certainly a real problem that needs
  to be addressed.
* Ensure all entry point names are unique and that there are no collisions.
  Maybe this can be done on registration?
* Special case where all groups are same size and there is an external vector of
  that size?
* Add capability to specify functions in non-standard ways (e.g. `base::sum`, or
  `(get("sum", as.environment("package:base"))`)?  Maybe not, that seems like
  potential trouble.  Certainly document also things like `f <- sum; f(x)`.
* Is it faster to compute complex expressions pairwise (i.e. full vector scan of
  two vectors), or do each row in full once?
* Look into using R_GetCCallable (see WRE) instead of what we're doing now.  It
  seems though that to do so we'll need to generate a full package which will
  further slow down the compilation.  What does `inline` do?
* Check name isn't used already.
* `?SHLIB` states some binary distributions don't include `R CMD SHLIB`.
* Figure out how to call the current version of R (e.g. `RD CMD SHLIB`).
* See how far back this works in terms of R versions.
* What happens when this stuff is serialized?
* Is there an alternative to R_FindSymbol?  Can we get it to be made part of the
  API.
* Can we use this in some way for e.g. really wide matrices where each column
  takes the place of an argument?  Generating a pointer for each column then may
  be less efficient.
* Lags and similar (i.e. `x[i] = x[i] * x[i - 1]`).
* Re-use repeated expressions.

