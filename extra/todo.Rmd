# To Do / Questions

* Can we have zero length data?  We should be able to.
* Ensure partial condition is good on the new implementation (in particular,
  still feels weird that it doesn't matter what the bounds types are).
* Make overflow testable.
* Test that everything works if there is no group varying data (i.e. everything
  fed through MoreArgs).  Not completely trivial to test as we need a function
  that allows us to specify a `data` parameter, but then uses it as a control
  instead of data (at least for `group_exec`).  We just need the group varying
  data to be referenced somewhere in the call, which 
* Recycle warning for windows, does it make sense?  It might with the partial
  windows, but for the main section we should only need to check once?  This is
  actually significant for the `w=1` case, taking about 40% of the time the
  function evaluation takes (`r2c_sum`).  But probably in the noise for all
  other cases.

## For CRAN

* Image links from README should be to raw github URLs.
* Figure out why winbuilder doesn't work.
* Errors in `match.call` that show the deparsed argument might deparse
  differently on different systems (`group_sum` error tests).
* Add iterator breaks?

## Other

* Special case of constant result lengths could be an optimization for group
  where we don't have to generate the vector, although there should always be
  few groups relative to vector elements, so complexity not worth it?
* Migrate to tapply structure.  More generally, explain interface?
* Allow more then `INT_MAX` groups (labels are limiting right now)?
* What if compilation fails, do we have good error messages?
* Don't use double for group sizes unless we have groups that are too large.
  **probably not worth it** b/c the group sizes result is only as big as the
  number of groups, so very small in the grand scheme of things.  First level is
  simply to check input vector size, and if less than `INT_MAX` use that, next
  step would be to switch from int to double if we do have a vector that exceeds
  the size limit (but then we need to test for that...).  Does that mean we need
  a limit to int?  Will be annoying to have logic for both.
* Should sorted be "assume.sorted"?  Probably.  Could add check that it is (see
  next).
* Process groups might be able to determine that things are sorted?  If things
  are always e.g. increasing, then it must be the case that they are sorted.
  Evaluate the overhead of this; should be low as it would just be done in the
  second pass that stores the sizes?  Something still needs to be declared as
  sorted though.  It's relatively cheap to check that it is, but not so cheap
  that we would always want to run that check.
* Perhaps we got too lazy with POW, do we need to handle all the other cases
  arith handles?  Maybe, but if we do we'll likely need our own `pow` function,
  as it stands right now we're likely to get non-identical results in the case
  of NA or Inf (or at least particular variations of them).
* Re-implement modulo.
* The `check=TRUE` might be better done with an explicit check function.
* For running function directly, can we pass data as an env so the traceback
  doesn't explode (but make sure this doesn't cause reference / refcount issues)?
* What is the implementation cost of allowing internal functions to advance the
  data pointers so they don't have to be manually moved after each function
  iteration?
* Implement sum64 and mean64 to use double accumulator (note we've tested that
  double accumulators are slower).
* We can no longer use `mean <- mean.default` and `r2c` at same time (this might
  be correct, but will make readme a bit more complicated).  Also, error message
  is very confusing in this case as `mean.default` is also from the base
  namespace, even though the masking is defined at the global level.
* Currently we require at least one data column so we can get away with using
  the group logic for the stand alone evaluation of the r2c funs.
* Add destructors that will unload the shlib and delete file file when the
  corresponding object is garbage collected (finalizer).
* Add check to `r2c` funs that verify the `r2c` version, the R version, and the
  platform (anything else)?
* Figure out a better way to store the object than embedding it with `bquote` in
  the function (e.g. retrieve from the call like `rlang`, but not sure that's
  better).
* Think about `df %>% group_by(g) %>% filter(x > min(df$x)`.  This should
  resolve naturally if we allow `[['x']]` as "normal" expression.
* Can we optimize label generation for cases where the last step is constant
  size or size of groups?
* Better introspection tools for intermediate products so we can see what they
  are.
* Are names sufficient to disqualify from nakedness?  How do names behave in
  recycling?  Do we want to allow other attributes to persist?
* Make sure to have a function that uses the `ctrl` functionality to check that
  it works properly (once we switch to `flag` for most functions).
* Can we get more memory efficient by e.g. using `+=` to avoid having to have
  memory allocated for both LHS and RHS for the arithmetic operators?  Might
  complicate things substantially.
* Make sure pointer arrays are aligned.  Use `malloc`?  If so internal code
  cannot use `error`, and we can't guarantee that?  Can we register a finalizer
  somehow (probably will need to).
* To allow assignments we can just use a series of nested environments such that
  each sub-call will then seek the symbol through the nested environments.
  We'll need to bind the data symbols to e.g. environments so they may be
  uniquely identified and we can confirm they've been found.
* Make sure headers go in in correct order; it may not work if we structure
  workflow around C functions?  Maybe okay if each group of functions does the
  right thing?  Do we need to include the headers before each group of
  functions?  Do we need to keep translation units independent (but the lose the
  benefit of static funs)?  This is almost certainly a real problem that needs
  to be addressed.
* Ensure all entry point names are unique and that there are no collisions.
  Maybe this can be done on registration?
* Special case where all groups are same size and there is an external vector of
  that size?
* Complex expressions with curly braces, etc.
* Unary arithmetic funs.
* Add post-processing of function result (e.g. to attach names, etc, as in
  `quantile`).
* Support for functions with defaults that need to be evaluated?  No.  This
  substantially increases complexity because we have to do so in the function
  evaluation environment and need access to all the other arguments.
* Side effects from evaluation of control parameters?  Where should assigned
  variables reside?
* Add capability to specify functions in non-standard ways (e.g. `base::sum`, or
  `(get("sum", as.environment("package:base"))`)?  Maybe not, that seems like
  potential trouble.  Certainly document also things like `f <- sum; f(x)`.
* Make sure there are interrupts.  Can we use "R_ext/Intermacros.h".  It seems
  yes generally, but they are not explicitly part of the API, and then there is
  the question of whether it makes sense to do so, or if we should just be doing
  this at the group level?
* Is it faster to compute complex expressions pairwise (i.e. full vector scan of
  two vectors), or do each row in full once?
* Look into using R_GetCCallable (see WRE) instead of what we're doing now.  It
  seems though that to do so we'll need to generate a full package which will
  further slow down the compilation.  What does `inline` do?
* Check name isn't used already.
* `?SHLIB` states some binary distributions don't include `R CMD SHLIB`.
* Figure out how to call the current version of R (e.g. `RD CMD SHLIB`).
* See how far back this works in terms of R versions.
* What happens when this stuff is serialized?
* Is there an alternative to R_FindSymbol?  Can we get it to be made part of the
  API.
* Can we use this in some way for e.g. really wide matrices where each column
  takes the place of an argument?  Generating a pointer for each column then may
  be less efficient.
* Does altrep play into this in any way?
* Lags and similar (i.e. `x[i] = x[i] * x[i - 1]`).
* Re-use repeated expressions.

## Done

* Be sure to test a window that is wider than the data to see that partial
  windows are computed correctly on both sides?  Should be okay.
* `DYNLOAD` warnings around `run()`; maybe that function doesn't need to be of
  the type DYNLOAD?  We know what the interface of it is, so we just need to
  check whether that's compatible with R's compilation mechanism.
    * Turns out R-devel was in a weird state where their own transition from
      empty arglist was incomplete.
* We should be able to specify align values that exceed the window range.
* Tests groups that aren't just 1:n or 0:n (I think we do this)?
* Test on windows.  Instructions for windows users about toolchain, etc?
* Fill out acknowledgments.
* Rename `mean0` to `mean1`
* Benchmarks:
  * Randomly ordered groups?
  * Larger group sizes?
* Try to interfere with r2c funs.  Need to document exactly what environment
  they are exposed to (base namespace).
* Pass data around in environments for better deparse (can't do this because the
  parameters might be unnamed via dots, or at least not easily, plus it only
  matters for the naked call).
* Add tests:
    * For parenthesis removal in mechanics.
    * For square tranform.
* When we dropped the use of env to match the arguments, how did keep track of
  the environment to look up functions in?  We don't, we just check function
  validity at run time.
* Emit warning/errors with the function call.
* Can we come up with a better error message for the matching of arguments?  Do
  we need our own matching instead of relying on `match.call`.
* Check dots with names (i.e. names that don't match formas but are caught by
  dots).  What should be done with these?  They probably should be unnamed.
* Check dots with multiple sets of dots, trying to e.g. pass both to group
  varying and flags/control params.
* Can we truly support dots (I think so, see dots section).
* Does arg order matching make sense?  We get: `function (y, x, ..., na.rm)` out
  of `r2cq(y - sum(x, na.rm = na.rm, ...), check = TRUE)`, dots get moved up,
  doesn't seem right.
* Are we checking that the functions resolve correctly at run time (and not just
  at compile time)? Yes, we check in `alloc`.
* Test that dots still work after we changed the eval environment; almost
  certainly won't so we have to think how to handle things that get matched to
  e.g. `..1`, etc.
* How can we efficiently warn of "longer object length is not a multiple" in
  vecrec?  We don't want a modulo for each group.  But we could check that the
  shorter object has not hit its length at the end of the loop and set a global
  variable?  Or use `flags` to communicate back?  When we compute each
  interaction size, we do (or could know) the group sizes, including possibly
  max and min group size.  But to be certain of a multiple you must be certain
  that there are no groups of odd sizes...  So I think it has to be done at run
  time, annoyingly.
* Do we need to handle the issue of `envir` for `match.call` at allocation time
  instead of at compile time?  Seems like the way this goes wrong is if the
  expression being looked at itself contains dots, e.g. literally `sum(...)`
  where the `...` need to be fetched.

    > (\(...) r2cq(sum(...)))(1, 2)
    Error in match.call(definition = definition, call = call, envir = envir,  : 
      ... used in a situation where it does not exist

Right now preprocess is just using `parent.frame()` for match.call, which
doesn't make any sense.

* Check assumption that double will hold `R_xlen_t`?  Or that length is no
  longer that the allowable size?  A bit tricky; no way to know what double size
  is.  This is because we return the group size to R; otherwise it would just be
  an R_xlen_t vector.  We need this to get the group max for the allocation.
  It's possible R guarantees this will be no bigger than e.g. 2^53 or some such.
  We added a check to assumptions.c.
* Ensure that all pointer parameters are allocated one extra element at end so
  that we can use the fun(++pointer) pattern without worrying about the last
  call overflowing (I think this might be allowed by the standard anyway,
  check).  Yes, allowed by C99 6.5.6 p8.
* Is it possible that set.seed could interfere badly with the random file name
  generation?  Yes, maybe try to initialize the pool
* Evaluation of non-compilable expressions in an env child of an env with
  appropriate symbols protected?  Such would be the symbols in the data, but
  what about the functions that are used?  That seems excessive.  No, we won't
  support this.
* Think though corner case of R_NA, NaN, Inf, etc: are we preserving semantics.
  Yes, mostly, but maybe not always (e.g. when we use `pow` instead of `square`)
* Look into GraalVM, Renjin?
* Only sort the columns that are used.  This is the case already as only things
  that match to the `r2c_fun` are submitable.
* Be sure to test situations where we have external data larger and smaller than
  group sizes.
* What do we do with NA groups?  Each it's own, or one big NA group?  One big NA
  group.  Single group; now documented.
* Document that we assume IEEE-754 (and thus existence of infinity and no
  overflow on conversion from long double to double), and check whether this is
  a reasonable assumption under C99 (probably no), or failing that under R.
* Figure out why external vectors are being duplicated.  Were seeing:

    Browse[2]> .Internal(inspect(alloc$alloc$dat[[5]]))
    @7fe16de86b68 14 REALSXP g0c0 [MARK,REF(65535)]  1 : 3 (compact)
    Browse[2]> .Internal(inspect(alloc$alloc$dat[[6]]))
    @7fe16de8b7b8 14 REALSXP g0c0 [MARK,REF(65535)]  1 : 3 (compact)

  for the slope calculation with y as 1:3 (literal).  Duh, is this just because
  we use `as.numeric`.

* Really need to figure out whether we want a formal interface to the functions.
  It could be auto-generated from all the unbound symbols like gsubfn does it.
* Annotate code with the call that it corresponds to


