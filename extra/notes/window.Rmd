

# Window Implementation

## Offset Direction

It really makes more sense for the offset to be the negative of what it is now.

## Start End

Does partial make sense for `rollby_`?  Should start end really subset, or
simply set where we start.  The latter is increasingly attractive.  What is the
correspondence with `rolli`?

We do really consider subsetting to be out of bounds of what this does.
Although it would be nice and could do it.

Actually, increasingly thinking that partial just doesn't make sense other than
for the regularly spaced data where you would expect a specific count of
observations inside the window.  There is the argument that you want windows to
have the same amount of "eligible space", but that's also achievable by setting
`start` and `end` at reasonable points wrt to `x`.

## Incomplete

A window is considered incomplete if the beginning of the data is to the right
of the left end of the first window, or the opposite.

So if:

    ileft == 0 && index[ileft] > left ||
    iright == imax && index[iright] < right

## Rationalize

We can rationalize the integer case to be:

* `width = n - 1`
* `bounds = "[]"`
* `index = seq_along(<data>)`

And it will be somewhat slower.  The biggest issue is that `seq_along()` could
return either numeric or integer, and we don't want to generate that whole
vector.  Maybe we just let it exist for this reason alone.  It would require a
bit of contortion to handle the special iterative case?

Maybe not, we would need to check whether the object is altrep sequence starting
at 1 and with a stride of 1, and then we could, for just the "[]" bounds case,
make the condition to check for be against the `i` instead of `index[ileft]`.

## Discrete vs Continuous

Is the "irregular" mode really about using a continuous variable, and thus the
base index points to a zero-width instantaneous moment (`POSIXct`?).  Whereas
instead the normal mode is pointing to a fixed width element.  What about
something like a `Date`?  Which is it?  If it is continuous, do we just take it
to be the instant the day switches, midnight?  Does it belong to the prior or
the subsequent day?

## Closed / Open intervals

Related to the above, how do we treat the ends of a window?  Do we give the
option of how to treat them?  What should be the default.

It's tricky because there is no consistent answer.  For no overlapping windows,
we get `n` if align is left or center, but `n-1` if it is right.

I think what makes most sense is to have a half closed interval.  We're picking
open on the right, so that e.g. if we pick a date, and we right align with width
1 day, we'll get all the entries from the prior day excluding anything that
happened at midnight, which we consider part of the current day.

Maybe in the future we'll give the option to do something different.

## End condition

Struggling a little bit to figure out the natural end condition.  If `align =
"left"` then it makes sense to have as many iterations as intervals.  We don't
need end to get a go at being an base index because it is included in the prior
window (notwithstanding smaller windows, etc.).

I guess `end` needs a shot at being a window because there is no guarantee it
was included in the prior window.  And it seems weird to use presence in the
prior window as reason to give it a shot or not, although in the special case of
`width = by` it does produce a "pleasing" outcome.

## Alternative Irregular Windows

Firstly we clearly need to rename our things.  There window size, window
spacing, and window contents.  Our implementation is regular in the first two.
We could allow:

* Specifying indices.
* Specifying window positions (where these could be the same as indices to
  simulate what slider does).
* Specifying window start/end points (equivalent to positions with variable
  widths?)

What should the names be?  Current `window_i_exec` is not actually irregular.

* Is it step vs. slide?  But both are step.
* Discrete vs continuous?
* Integer vs real?  Maybe.
* `window`
* `window_c`
* `window_ci`, this replaces `by` with `at`?

    gexe(fun, groups, data, MoreArgs, enclos)
    wexe(fun, width, data, MoreArgs, by, partial, align, enclos)
    wcexe(fun, width, data, MoreArgs, by, partial, align, enclos)
    wciexe(fun, width, index, data, MoreArgs, by, partial, align, enclos)

    gexe(fun, d, g, args, enclos)
    wexe(fun, d, w, by, align, partial, args, enclos)
    wcexe(fun, d, i, w, by, align, partial, args, enclos)
    wciexe(fun, d, i, w, at, align, partial, args, enclos)

    g_exe(fun, data, g, args, enclos)
    # discrete regular
    wd_exe(fun, data, w, by, align, partial, args, enclos)
    # continuous regular
    wc_exe(fun, data, i, w, by, align, start, end, partial, args, enclos)
    # continuous irregular
    wi_exe(fun, data, i, w, at, align, start, end, partial, args, enclos)

    g_exe
    wd_by_exe
    wd_at_exe
    wc_by_exe
    wc_at_exe

    g_exe

    wdby_exe
    wdat_exe

    wcby_exe
    wcat_exe

So is there a way to merge the discrete and continuous interfaces into one?  Not
really, they are pretty different.  But continuous can completely cover the
discrete case.

Actually, they are pretty close because the following produce the same value:

    wd_by(x, w=<odd number>)
    wc_by(x, seq_along(x), w=<odd number>)

One issue remaining is how to treat "align='right'".  In continuous it excludes
the base index value due to the open interval on the right.  But in discrete it
includes it.  If we defined it as `right = width - 1`, it works in continuous
too?

    |1|0|1|2|3|
        ^
      [ | )
      ( | ]
    [ | | | )
    ( | | | ]



    rolli_exec(f, data, n, align, by, partial, MoreArgs, enclos)

    rollby_exec(
      f, data, width, offset, by, x, start, end, bounds, partial,
      MoreArgs, enclos
    )
    rollat_exec(
      f, data, width, offset, at, x, bounds, partial, MoreArgs, enclos
    )
    rollin_exec(
      f, data, width, offset, x, left, right, bounds, partial, MoreArgs, enclos
    )


    rollby_exec(
      f, data, width, offset=w/2,
      x=seq_along(if(is.list(data)) data[[1L]] else data),
      by=(end - start) / (length(x) - 1L),
      start=x[1], end=x[length(x)],
      bounds="[)",
      partial=FALSE,
      MoreArgs=list(),
      enclos=parent.frame()
    )
    rollat_exec()

    auto_exec <- function(f, exec, ...) {

    }

    rollsum3 <- auto_exec(r2c_sum, roll_exec, width=3)
    rollsum3(1:10, align='right')






    w_exe(r2c_sum, x, w=5, partial=TRUE, args=list(na.rm=FALSE))
    g_exe(r2c_sum, x, g, na.rm=TRUE)

    wat_exe(
      f, x, w,
      i=seq_along(x), at=i, align='center',
      partial, args, enclos
    )

    winx()
    winatx()
    grpx()

    winX()
    winatX()
    grpX()

    window_by_exec
    window_at_exec




What does `partial` mean for the continuous case?

## r2c

Advance: group size -> by
Length: group size -> window

Additionally, need to handle cases where the window overflows and fill it.

Currently we advance the data pointer by group size, but instead we want to
advance by 'by'.

So we need to split the `grp_lens` into those two different things, that are the
same for the group mode.

Additionally, we need to add support for the recycling of the indices.  For
simplicity we could start by recycling them in R?  Not ideal as it creates big
vectors that are completely unnecessary for the default case of scalar offset
and scalar window.  And these vectors are large.

Need to ensure that we have nothing in the offset vector that causes a problem.

Likely want a special branch for the scalar-scalar default case.

Currently the code assumes that `g_lens` is equal in size to the number of
offsets, which certainly won't be the case if we're recycling.  This also means
that the looping is completely different because for the window case we're
recycling offset and group size until the time we run out of data.  So we're
going to have a double nested loop with a break.

We need a check that the final result is scalar as it's not guaranteed ex-ante?
We could guarantee it ex-ante, but that's dangerous if we're wrong (but then all
our size calculations would be wrong anyway).

What if we allow non-scalar results?  Probably immediate complication is that we
can't just go straight to "NA" result when windows are OOB.  If we do resolve
that, we need to do a first pass pre-computing the result vector size.

For now focus on developing the scalar step and scalar window size, and
recognize the possibility for:

* Vector of steps.
* Vector of window sizes.
* A location vector to allow data to have different positions than their rank
  in the input vector.

## For Benchmarks

* slider
* data.table
* zoo rollapply


## Others Window Implementations

### data.table

#### Key Points

* Slow and fast algorithm
* Adaptive width

#### Details

https://github.com/Rdatatable/data.table/pull/5441#issuecomment-1236104263

### Slider

#### Key Points

* Irregular series can still be windowed when providing an index.
* Uses segment trees for the fast calculations to reduce cost from O(n^2) to
  O(nlogn)
* Uses before/after instead of left/center/right for more flexible window
  computation.

#### Details

Interesting mention of "segment trees".  This allows to partially cache sums by
pre-aggregating the vector in a binary fashion, and then re-using the aggregates
when possible.

Also interesting that instead of using "left", "right", etc., it uses before and
after.

Would it work with variance?  What does it generalize to?

    sum((x - mean(x))^2)

Default is to return a list.

Concept of index column for irregular series.

Referenced paper also has a few other interesting topics:

* Partitions, where you compute the sliding function within each partition
  independently.
* Variable size windows, where you cannot easily deal with removal/addition
  window because you don't know how much you need to remove/add and doing so
  could require scanning the entire thing again.

We can compute the variance of two buckets from the individual stats according
to "Maintaining variance and k-medians over data stream windows." (referenced in
[1])

    n<i,j> = n<i> + n<j>
    u<i,j> = (n<i>*u<i> + n<j>*u<j>) / (n<i> + n<j>)
    V<i,j> = V<i> + V<j> + (n<i>*n<j> / n<i,j>) * (u<i> - u<j>)^2

So it should be possible to derive the equivalent formulas for most statistics
for combining buckets, but there might not be an automatic way of doing so given
a function (hard to believe there would be looking at the above).  Once we have
the statistics we can use segment trees to govern how we combine things.

So ultimately this business comes down to how much it costs in common use cases
to re-run the entire function.

[1]: https://www.researchgate.net/publication/221559611_Variance_estimation_over_sliding_windows/link/56a2194208ae2afab885c5ba/download

### runner

Doesn't seem to add too much interesting.

